---
title: 'Manual model development'
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---


# MVP

You are given a set of data on housing sale prices for the last few years in King County (near Seattle) between May 2014 and May 2015.

<br>
<div class="emphasis">
We want you to build an **explanatory model** for the `price` of housing in King County, i.e. an interpretable model in which the included variables are statistically justifiable.

The variable definitions are:

`id` - Unique ID for each home sold  
`date` - Date of the home sale  
`price` - Price of each home sold  
`bedrooms` - Number of bedrooms  
`bathrooms` - Number of bathrooms, where .5 accounts for a room with a toilet but no shower  
`sqft_living` - Square footage of the apartments interior living space  
`sqft_lot` - Square footage of the land space  
`floors` - Number of floors  
`waterfront` - A dummy variable for whether the apartment was overlooking the waterfront or not  
`view` - An index from 0 to 4 of how good the view of the property was  
`condition` - An index from 1 to 5 on the condition of the apartment  
`grade` - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design  
`sqft_above` - The square footage of the interior housing space that is above ground level  
`sqft_basement` - The square footage of the interior housing space that is below ground level  
`yr_built` - The year the house was initially built  
`yr_renovated` - The year of the houseâ€™s last renovation  
`zipcode` - What zipcode area the house is in  
`lat` - Lattitude  
`long` - Longitude  
`sqft_living15` - The square footage of interior housing living space for the nearest 15 neighbors  
`sqft_lot15` - The square footage of the land lots of the nearest 15 neighbors  
</div>
<br>

# Question 1 

Tidy up the data ready for regression:

    * You might like to think about removing some or all of `date`, `id`, `sqft_living15`, `sqft_lot15` and `zipcode` (`lat` and `long` provide a better measure of location in any event).
    * Have a think about how to treat `waterfront`. Should we convert its type?
    * We converted `yr_renovated` into a `renovated` logical variable, indicating whether the property had ever been renovated. You may wish to do the same.
    * Have a think about how to treat `view`, `condition` and `grade`? Are they interval or categorical ordinal data types?


```{r, message=FALSE}
library(GGally)
library(modelr)
library(tidyverse)
```

```{r}
houses <- read_csv("data/kc_house_data.csv")
glimpse(houses)
```

```{r}
# tidy up data. In particular treat condition and grade as factor, as they are
# ordinal categorical
houses_tidy <- houses %>%
  select(-c("id", "date", "sqft_living15", "sqft_lot15", "zipcode")) %>%
  mutate(waterfront = as.logical(waterfront)) %>%
  mutate(renovated = yr_renovated != 0) %>%
  select(-"yr_renovated") %>%
  mutate(view = as_factor(view)) %>% 
  mutate(condition = as_factor(condition)) %>%
  mutate(grade = as_factor(grade))

glimpse(houses_tidy)
```

<br>


# Question 2

Check for aliased variables using the `alias()` function (this takes in a formula object and a data set). [**Hint** - formula `price ~ .` says 'price varying with all predictors', this is a suitable input to `alias()`]. Remove variables that lead to an alias. Check the 'Elements of multiple regression' lesson for a dropdown containing further information on finding aliased variables in a dataset.

**Solution**
<br>

```{r}
# Alias is useful to check if we have aliased variables, i.e. one or more
# variables that can be computed from other variables
alias(price ~ ., data = houses_tidy)

# seems that sqft_basement can be computed from sqft_living - sqft_above.
# let's drop sqft_living leaving just the two contributions sqft_basement and 
# sqft_above
houses_tidy <- houses_tidy %>%
  select(-"sqft_living")

glimpse(houses_tidy)
```

<br>


# Question 3

Systematically build a regression model containing up to **four** main effects (remember, a main effect is just a single predictor with coefficient), testing the regression diagnostics as you go

    * splitting datasets into numeric and non-numeric columns might help `ggpairs()` run in manageable time, although you will need to add either a `price` or `resid` column to the non-numeric dataframe in order to see its correlations with the non-numeric predictors. You can do it in the following way:

```{r}
houses_tidy_numeric <- houses_tidy %>%
  select_if(is.numeric)

houses_tidy_nonnumeric <- houses_tidy %>%
  select_if(function(x) !is.numeric(x))

houses_tidy_nonnumeric$price <- houses_tidy$price
```


**Solution**
<br>

```{r}
ggpairs(houses_tidy_numeric)
ggpairs(houses_tidy_nonnumeric)
```

You can also subset your ggpairs plot doing the following: 

<br>

```{r}
ggpairs(houses_tidy_numeric, columns = c(1, 2, 3, 4))
```


and the same in subsequent rounds of predictor selection with the `resid` column.<br><br>


Remember, if you are not sure whether including a categorical predictor is statistically justified, run an `anova()` test passing in the models with- and without the categorical predictor and check the p-value of the test.


```{r, message=FALSE}
houses_tidy_numeric <- houses_tidy %>%
  select_if(is.numeric)

houses_tidy_nonnumeric <- houses_tidy %>%
  select_if(function(x) !is.numeric(x))

houses_tidy_nonnumeric$price <- houses_tidy$price

ggpairs(houses_tidy_numeric)
ggpairs(houses_tidy_nonnumeric)
```



Correlation of `sqft_above` with `price` looks pretty promising, but split of `price` by `grade` and `waterfront` also look decent.

```{r}
houses_tidy %>%
  ggplot(aes(x = grade, y = price)) +
  geom_boxplot()

houses_tidy %>%
  ggplot(aes(x = waterfront, y = price)) +
  geom_boxplot()
```

Start building the models:

```{r}
# model with price and sqft above
mod1a <- lm(price ~ sqft_above, data = houses_tidy)
summary(mod1a)
```

```{r}
mod1b <- lm(price ~ grade, data = houses_tidy)
summary(mod1b)
```

```{r}
mod1c <- lm(price ~ waterfront, data = houses_tidy)
summary(mod1c)
```

Grade looks the most promising, but some of the grade level coefficients are insignificant.

From the F-test at the bottom of the regression output tests against the null model (i.e. intercept only). But, if we want, we can replicate this using a separate anova. For this, our null model would be to regress price on intercept only. 

You can do this in the following way:

```{r}
null_model <- lm(price ~ 1, data = houses_tidy)
grade_model <- lm(price ~ grade, data = houses_tidy)
anova(null_model, grade_model)

# grade is significant, let's keep it. Now plot diagnostics
par(mfrow = c(2, 2))
plot(mod1b)
```


```{r}
houses_resid <- houses_tidy %>%
  add_residuals(mod1b) %>%
  select(-c("price", "grade"))

houses_resid_numeric <- houses_resid %>%
  select_if(is.numeric)

houses_resid_nonnumeric <- houses_resid %>%
  select_if(function(x) !is.numeric(x))

houses_resid_nonnumeric$resid <- houses_resid$resid
```

```{r, message=FALSE}
ggpairs(houses_resid_numeric)
ggpairs(houses_resid_nonnumeric)
```


Our predictor `lat` has highest correlation with residuals, but `waterfront` and `view` look pretty promising. Try all three...


```{r}
mod2a <- lm(price ~ grade + lat, data = houses_tidy)
summary(mod2a)
```


```{r}
mod2b <- lm(price ~ grade + waterfront, data = houses_tidy)
summary(mod2b)
```

```{r}
mod2c <- lm(price ~ grade + view, data = houses_tidy)
summary(mod2c)
```

```{r}
# lat is significant and has a slightly higher r^2, let's keep model2a
par(mfrow = c(2, 2))
plot(mod2a)
```


```{r}
houses_resid <- houses_tidy %>%
  add_residuals(mod2a) %>%
  select(-c("price", "grade", "lat"))

houses_resid_numeric <- houses_resid %>%
  select_if(is.numeric)

houses_resid_nonnumeric <- houses_resid %>%
  select_if(function(x) !is.numeric(x))

houses_resid_nonnumeric$resid <- houses_resid$resid
```

```{r, message=FALSE}
ggpairs(houses_resid_numeric)
ggpairs(houses_resid_nonnumeric)
```

Now `sqft_basement` has strongest correlation with residuals, but also compare against model with `waterfront` and `view`.

```{r}
mod3a <- lm(price ~ grade + lat + sqft_basement, data = houses_tidy)
summary(mod3a)
```

```{r}
mod3b <- lm(price ~ grade + lat + waterfront, data = houses_tidy)
summary(mod3b)
```

```{r}
mod3c <- lm(price ~ grade + lat + view, data = houses_tidy)
summary(mod3c)
```

```{r}
# view model is best, keep mod3c
par(mfrow = c(2, 2))
plot(mod3c)
```


```{r}
houses_resid <- houses_tidy %>%
  add_residuals(mod3c) %>%
  select(-c("price", "grade", "lat", "view"))

houses_resid_numeric <- houses_resid %>%
  select_if(is.numeric)

houses_resid_nonnumeric <- houses_resid %>%
  select_if(function(x) !is.numeric(x))

houses_resid_nonnumeric$resid <- houses_resid$resid
```

```{r, message=FALSE}
ggpairs(houses_resid_numeric)
ggpairs(houses_resid_nonnumeric)
```

`sqft_basement` has highest correlation with residuals. Let's test against all remaining categorical predictors:

```{r}
mod4a <- lm(price ~ grade + lat + view + sqft_basement, data = houses_tidy)
summary(mod4a)
```

```{r}
mod4b <- lm(price ~ grade + lat + view + waterfront, data = houses_tidy)
summary(mod4b)
```

```{r}
mod4c <- lm(price ~ grade + lat + view + condition, data = houses_tidy)
summary(mod4c)
```

```{r}
mod4d <- lm(price ~ grade + lat + view + renovated, data = houses_tidy)
summary(mod4d)
```

```{r}
# looks like model with sqft_basement is best, keep mod4a
par(mfrow = c(2, 2))
plot(mod4a)
```

```{r}
houses_resid <- houses_tidy %>%
  add_residuals(mod4a) %>%
  select(- price)
```

Our final model in terms of main effects is: `price ~ grade + lat + view + sqft_basement`


<br>


# Extensions

* Consider possible interactions between your four main effect predictors and test their effect upon $r^2$. Choose your best candidate interaction and visualise its effect. 

* Calculate the relative importance of predictors from your best $4$-predictor model (i.e. the model without an interaction). Which predictor affects `price` most strongly?

**Solution**
<br>

Now, for interactions, have six possibilities that obey principle of strong hierarchy (i.e. consider including an interaction only if its main effects are already present in the model)

```{r}
mod5a <- lm(price ~ grade + lat + view + sqft_basement + grade:lat, data = houses_tidy)
summary(mod5a)

mod5b <- lm(price ~ grade + lat + view + sqft_basement + grade:view, data = houses_tidy)
summary(mod5b)

mod5c <- lm(price ~ grade + lat + view + sqft_basement + grade:sqft_basement, data = houses_tidy)
summary(mod5c)

mod5d <- lm(price ~ grade + lat + view + sqft_basement + lat:view, data = houses_tidy)
summary(mod5d)

mod5e <- lm(price ~ grade + lat + view + sqft_basement + lat:sqft_basement, data = houses_tidy)
summary(mod5e)

mod5f <- lm(price ~ grade + lat + view + sqft_basement + view:sqft_basement, data = houses_tidy)
summary(mod5f)

# mod5c looks like the best
par(mfrow = c(2,2))
plot(mod5c)
```

It seems that the `grade:sqft_basement` interaction leads to highest $r^2$ (but two levels of the interaction cannot be determined due to fitting problems).

Now let's see a visualisation of the effect of this interaction.

```{r}
houses_resid %>%
  ggplot(aes(x = sqft_basement, y = resid, colour = grade)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~ grade)
```

Relative importance of predictors:

```{r}
library(relaimpo)
calc.relimp(mod4a, method = "lmg", rela = TRUE)
```

It looks like the `grade` of property is the most important determiner of `price`, followed by how good the `view` of the property was.





